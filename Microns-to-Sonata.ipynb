{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceb2cbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "import morphio\n",
    "import conntility\n",
    "import os\n",
    "\n",
    "from scipy.spatial import distance\n",
    "\n",
    "root_morph = \"/gpfs/bbp.cscs.ch/project/proj3/projects-data/2023.12.18-microns-skeletonization\"\n",
    "conn_fn = \"/gpfs/bbp.cscs.ch/home/reimann/data/mm3/microns_mm3_connectome.h5\"\n",
    "\n",
    "root_morph_out = \"./translated\"\n",
    "root_sonata_out = \"./sonata\"\n",
    "sonata_edges = \"edges.h5\"\n",
    "sonata_nodes = \"nodes.h5\"\n",
    "node_population = \"default\"\n",
    "edge_population = \"default\"\n",
    "\n",
    "M = conntility.ConnectivityMatrix.from_h5(conn_fn, \"full\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd43ac52",
   "metadata": {},
   "source": [
    "# Read contents of root_morph.\n",
    "Finds all swc files in Marwan's morphology release and creates a Series where the index is the \"pt_root_id\" and the value is the path to the morphology file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fd16160",
   "metadata": {},
   "outputs": [],
   "source": [
    "subdirs = [_x for _x in os.listdir(root_morph) if _x.startswith(\"2023\")]\n",
    "\n",
    "def dir_to_series(root):\n",
    "    fns = [_x for _x in os.listdir(root) if \n",
    "           os.path.isfile(os.path.join(root, _x)) and \n",
    "           os.path.splitext(_x)[1] == \".swc\"]\n",
    "    return pandas.Series([\n",
    "        os.path.join(root, _x) for _x in fns\n",
    "    ], index=[\n",
    "        int(os.path.splitext(_x)[0]) for _x in fns\n",
    "    ])\n",
    "\n",
    "morph_series = dir_to_series(os.path.join(root_morph, subdirs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ae24c7",
   "metadata": {},
   "source": [
    "# Generate subnetwork\n",
    "Create the subgraph of M that contains all nodes that are contained in the release, plus the edges between them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b13a7470",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup = M._vertex_properties[\"pt_root_id\"].reset_index().set_index(\"pt_root_id\")[\"index\"]\n",
    "S = M.subpopulation(lookup[morph_series.index].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065926bf",
   "metadata": {},
   "source": [
    "# Translate morphologies\n",
    "This is not strictly necessary, but we prefer morphologies that are centered with their soma at the origin.\n",
    "The location of the neuron is then given as a node property.\n",
    "\n",
    "Here, we create copies of all morphologies that are translated by the corresponding node location in M."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "083a3c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_morphology(m, offset, out_fn):\n",
    "    mm = m.as_mutable()\n",
    "    offset = offset.reshape((1, -1))\n",
    "    mm.soma.points = mm.soma.points - offset\n",
    "    for sec in mm.iter():\n",
    "        sec.points = sec.points - offset\n",
    "\n",
    "    m2 = mm.as_immutable()\n",
    "    mm.write(out_fn)\n",
    "    return m2\n",
    "\n",
    "morph_series_tl = {} # As morph_series, but for the translated morphology files\n",
    "\n",
    "for i, nrn in S.vertices.iterrows():\n",
    "    offset = (nrn[[\"x_nm\", \"y_nm\", \"z_nm\"]] / 1000).values.reshape((1, -1))\n",
    "    m = morphio.Morphology(morph_series[nrn[\"pt_root_id\"]])\n",
    "    _, fn_base = os.path.split(morph_series[nrn[\"pt_root_id\"]])\n",
    "    fn_out = os.path.join(root_morph_out, fn_base)\n",
    "    m2 = translate_morphology(m, offset, fn_out)\n",
    "    morph_series_tl[nrn[\"pt_root_id\"]] = fn_out\n",
    "\n",
    "morph_series_tl = pandas.DataFrame(morph_series_tl, index=[\"path\"]).transpose()[\"path\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539cbce3",
   "metadata": {},
   "source": [
    "# Create Sonata-compatible synapse DataFrame\n",
    "This is the only really complex step.\n",
    "While M.edges is already a DataFrame of synapse properties, we will have to make it Sonata compatible.\n",
    "\n",
    "That comprises renaming some columns, moving from nm to um. But also looking up the section and segment ids where all synapses are placed. So, we do a bit of 3d geometry here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "664ce440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def morphology(nrn):\n",
    "    m = morphio.Morphology(morph_series_tl[nrn[\"pt_root_id\"]])\n",
    "    return m\n",
    "\n",
    "def point_segment_distances(sec_pts, syn_locs):\n",
    "    dist_start = distance.cdist(syn_locs, sec_pts[:-1])\n",
    "    dist_end = distance.cdist(syn_locs, sec_pts[1:])\n",
    "\n",
    "    d_sec = numpy.diff(sec_pts, axis=0)\n",
    "    seg_len = numpy.linalg.norm(d_sec, axis=1, keepdims=True)\n",
    "    d_sec = d_sec / seg_len\n",
    "    d_syn = syn_locs.reshape((-1, 1, 3)) - sec_pts[:-1].reshape((1, -1, 3)) # syns x segs x 3\n",
    "    dist_syn = numpy.linalg.norm(d_syn, axis=-1, keepdims=True)\n",
    "    d_syn_norm = d_syn / dist_syn\n",
    "\n",
    "    cos_angle = (d_syn_norm * d_sec).sum(axis=-1)\n",
    "    pw_dist = numpy.sin(numpy.arccos(cos_angle)) * dist_syn[:, :, 0]\n",
    "\n",
    "    proj_dist = cos_angle * dist_syn[:, : , 0]\n",
    "    pw_dist[proj_dist < 0] = dist_start[proj_dist < 0]\n",
    "    pw_dist[proj_dist > seg_len.transpose()] = dist_end[proj_dist > seg_len.transpose()]\n",
    "    \n",
    "    seg_offsets = numpy.maximum(numpy.minimum(proj_dist, seg_len.transpose()), 0)\n",
    "    \n",
    "    return pw_dist, seg_offsets\n",
    "\n",
    "def point_sections_distances(m2, syn_locs):\n",
    "    all_pw_dist, all_offsets = zip(*[\n",
    "        point_segment_distances(_sec.points, syn_locs)\n",
    "        for _sec in m2.sections\n",
    "    ])\n",
    "    return numpy.hstack(all_pw_dist), numpy.hstack(all_offsets)\n",
    "\n",
    "def find_synapse_location_on_morphology(m2, syn_locs, soma_epsilon=1.0):\n",
    "    # Assumes morphology is centered on soma!\n",
    "    dist_from_soma = numpy.linalg.norm(syn_locs, axis=1)\n",
    "    is_on_soma = dist_from_soma < (soma_epsilon + m2.soma.diameters / 2)\n",
    "    \n",
    "    n_per_sec = numpy.diff(m2.section_offsets) - 1\n",
    "    \n",
    "    sec_lo = numpy.hstack([i * numpy.ones(n, dtype=int)\n",
    "                           for i, n in enumerate(n_per_sec)])\n",
    "    \n",
    "    all_pw_dist, all_offsets = point_sections_distances(m2, syn_locs)\n",
    "    D = numpy.min(all_pw_dist, axis=1)\n",
    "    idxx = numpy.argmin(all_pw_dist, axis=1)\n",
    "    \n",
    "    res_sec = sec_lo[idxx]\n",
    "    res_seg = idxx - numpy.cumsum(numpy.hstack([0, n_per_sec]))[res_sec]\n",
    "    res_off = all_offsets[numpy.arange(all_offsets.shape[0]), idxx]\n",
    "    \n",
    "    res_sec[is_on_soma] = -1\n",
    "    res_seg[is_on_soma] = 0\n",
    "    res_off[is_on_soma] = 0\n",
    "    D[is_on_soma] = numpy.maximum(dist_from_soma[is_on_soma] - m2.soma.diameters / 2, 0)\n",
    "    \n",
    "    return res_sec, res_seg, res_off, D\n",
    "\n",
    "def base_synapse_properties_df(m2, syn_locs, soma_epsilon=1.0):\n",
    "    res_sec, res_seg, res_off, D = find_synapse_location_on_morphology(m2, syn_locs, soma_epsilon)\n",
    "    sec_types = m2.section_types[res_sec]\n",
    "    sec_types[res_sec == -1] = 1 # SOMA\n",
    "    return pandas.DataFrame({\n",
    "            \"afferent_section_id\": res_sec,\n",
    "            \"afferent_segment_id\": res_seg,\n",
    "            \"afferent_segment_offset\": res_off,\n",
    "            \"afferent_section_type\": sec_types,\n",
    "            \"spine_length\": D\n",
    "        })\n",
    "    \n",
    "def synapse_properties_df(S, nrn, lst_additional_props):\n",
    "    m = morphology(nrn)\n",
    "    Ssub = S.filter(\"pt_root_id\", side=\"col\").eq(nrn[\"pt_root_id\"])\n",
    "    syn_locs = Ssub.edges[[\"delta_x_nm\", \"delta_y_nm\", \"delta_z_nm\"]].values / 1000\n",
    "    props = base_synapse_properties_df(m, syn_locs)\n",
    "    \n",
    "    xyz = Ssub.edges[[\"x_nm\", \"y_nm\", \"z_nm\"]].reset_index(drop=True) / 1000\n",
    "    props = pandas.concat([\n",
    "        xyz.rename(columns={\"x_nm\": \"afferent_center_x\", \"y_nm\": \"afferent_center_y\", \"z_nm\": \"afferent_center_z\"}),\n",
    "        props,\n",
    "        Ssub.edges[lst_additional_props].reset_index(drop=True)\n",
    "    ], axis=1)\n",
    "    \n",
    "    \n",
    "    idxx = pandas.DataFrame({\n",
    "        \"source_node_id\": Ssub._edge_indices.values[:, 0],\n",
    "        \"target_node_id\": Ssub._edge_indices.values[:, 1]\n",
    "    })\n",
    "    return props, idxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd832b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "props, idxx = zip(*[synapse_properties_df(S, nrn, [\"size\"]) for _, nrn in S.vertices.iterrows()])\n",
    "props = pandas.concat(props, axis=0).reset_index(drop=True)\n",
    "idxx = pandas.concat(idxx, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28bfb76",
   "metadata": {},
   "source": [
    "# Write EdgePopulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5aafabaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from libsonata import EdgePopulation\n",
    "\n",
    "if not os.path.exists(root_sonata_out):\n",
    "    os.makedirs(root_sonata_out)\n",
    "\n",
    "output_path = os.path.join(root_sonata_out, sonata_edges)\n",
    "population = edge_population\n",
    "\n",
    "with h5py.File(output_path, 'w') as h5:\n",
    "    grp = h5.create_group('/edges/{0}'.format(population))\n",
    "    for _col in idxx.columns:\n",
    "        grp.create_dataset(_col, data=idxx[_col].values.astype(numpy.int64))\n",
    "    \n",
    "    prop_grp = grp.create_group(\"0\")\n",
    "    for _col in props.columns:\n",
    "        prop_grp.create_dataset(_col, data=props[_col].values)\n",
    "        \n",
    "EdgePopulation.write_indices(\n",
    "        output_path,\n",
    "        population,\n",
    "        len(S),\n",
    "        len(S)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7861ff7",
   "metadata": {},
   "source": [
    "# Write NodePopulation\n",
    "Similarly, for the node population we have to rename some columns and move from nm to um."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bf898a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from voxcell import CellCollection\n",
    "\n",
    "relevant_cols = [\"pt_root_id\", \"cell_type\", \"tentative_region\"]\n",
    "tl = {\"tentative_region\": \"region\"}\n",
    "\n",
    "position_cols = [\"x_nm\", \"y_nm\", \"z_nm\"]\n",
    "tl_pos = {\"x_nm\": \"x\", \"y_nm\": \"y\", \"z_nm\": \"z\"}\n",
    "\n",
    "# morphology filename w/o root and extension\n",
    "_m_s = morph_series_tl.apply(lambda _x: os.path.splitext(os.path.split(_x)[1])[0])\n",
    "_m_s.name = \"morphology\"\n",
    "\n",
    "def append_quaternions(df_in):\n",
    "    df_q = pandas.DataFrame({\n",
    "        \"orientation_w\": numpy.ones(len(df_in)),\n",
    "        \"orientation_x\": numpy.zeros(len(df_in)),\n",
    "        \"orientation_y\": numpy.zeros(len(df_in)),\n",
    "        \"orientation_z\": numpy.zeros(len(df_in))\n",
    "    }, index=df_in.index)\n",
    "    return pandas.concat([df_in, df_q], axis=1)\n",
    "\n",
    "df = append_quaternions(\n",
    "    pandas.concat([S.vertices[relevant_cols].rename(columns=tl),\n",
    "                   S.vertices[position_cols].rename(columns=tl_pos) / 1000,\n",
    "                   _m_s[S.vertices[\"pt_root_id\"]].reset_index(drop=True)],\n",
    "             axis=1)\n",
    ")\n",
    "df.index = numpy.arange(1, len(df) + 1)\n",
    "\n",
    "coll = CellCollection.from_dataframe(df)\n",
    "coll.save_sonata(os.path.join(root_sonata_out, sonata_nodes))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bluepysnap",
   "language": "python",
   "name": "bluepysnap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
